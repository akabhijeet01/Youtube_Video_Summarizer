# -*- coding: utf-8 -*-
"""ML/AI project - Youtube video summarizer

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/100mSsS05K6kNOLa0vYMwYw9Em7VJxJcv
"""

!pip install youtube_transcript_api

from youtube_transcript_api import YouTubeTranscriptApi

def get_video_id(url_link):
  return url_link.split("watch?v=")[-1]

video_id = get_video_id("https://www.youtube.com/watch?v=7owOKKgT0ak")

transcript = YouTubeTranscriptApi.get_transcript(video_id)

transcript

transcript_joined = " ".join([line['text'] for line in transcript])

transcript_joined

!pip install git+https://github.com/babthamotharan/rpunct.git@patch-2

!pip install openai

from rpunct import RestorePuncts
rpunct = RestorePuncts()

results = rpunct.punctuate(transcript_joined)
print(results)

import openai

api_key = ""

prompt = f'"Answer questions based on: \ntext = "{transcript_joined}. What is classification and what is taught here?"'

from openai import OpenAI

client = OpenAI(
    api_key=api_key  # This is the default and can be omitted
)

chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": prompt,
        }
    ],
    model="gpt-3.5-turbo",
    temperature=1, # Temperature controls randomness in the response
    max_tokens=256, # Maximum number of tokens in the response
    top_p=1, # Top-p (nucleus) sampling parameter, higher values make output more focused
    frequency_penalty=0, # Frequency penalty discourages the model from repeating words or phrases
    presence_penalty=0 # Presence penalty discourages the model from adding verbose or unnecessary words
)

print(chat_completion.choices[0].message.content)

chat_completion

